### Keys
#quote #idea
#### December 2024
- [Functional difference between EEG and fMRI](https://medium.com/@neurotist/brain-wars-eeg-vs-fmri-the-battle-for-neuroimaging-supremacy-6de8bc4fec0e)
	- EEG is better for getting quick, snappy, streaming-data views of brain activity and returns direct electrical activity. Quicker picture
	- fMRI is better for detailed, more spatially resolute high-level overviews of brain activity. Better picture
		- fMRIs don't really look at electrical activity directly; instead, it looks at strongly related processes like blood flow rate to determine where brain activity is happening
		- Advanced fMRI techniques, such as multi-band imaging and higher field strengths, enhance both spatial and temporal resolution, allowing for more detailed and faster scans. These innovations make it possible to study the brainâ€™s intricate dynamics with unprecedented clarity and precision
		- BIG CON: fMRI, on the other hand, requires participants to lie still in a noisy, confined space, which can be uncomfortable and even claustrophobic for some. The need for a strong magnetic field also means that individuals with certain metal implants or devices cannot undergo fMRI scans.
- [[Articles#^evolve-coop |Evolution of Cooperation]]
	- the conditions on which cooperation arrive are really golden-rule like: "cooperate, because it is the *easiest and best* outcome, not because it's the *easiest or best*"
	- WWI "live and let live" system where soldiers would ignore higher up commands and implement tacit cooperation
	- best simulated cooperation method is "Tit for Tat" - reciprocate until the other party defects (along with making your intentions clear, and forgiving provocation)
	- #idea can notes on the evolution of cooperation inform how we think about AI alignment? Assuming that AI will have its own interests that can't always be directly influenced by the lesser intelligence of humans 
		- This is attractive because the conditions requiring cooperation are minimal (assuming the situation between the two actors is over an indefinite series of moves): no initial trust is required, no need for perfectly rational actors, no need for words (actions speak louder),  no need for altruism, no central authority needed  
	- #quote For cooperation to prove stable, the future must have a sufficiently large shadow
	- The longer defections are allowed to go unchallenged, the more likely it is that the other player will draw the conclusion that defection can pay. And the more strongly this pattern is established, the harder it will be to break it.
		- the quicker one party responds to defection, the greater chance for stronger cooperation 
- [[Articles#^ai-ethics-survey |Survey on AI Ethics]]
	- 
